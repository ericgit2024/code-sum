# Configuration for Source Code Summarization Project

# Dataset Configuration
dataset:
  name: "code_x_glue_ct_code_to_text"
  language: "python"
  sample_size: 5000  # Scaled to 5000 for improved performance
  train_split: 0.7   # 3500 train
  val_split: 0.15    # 750 val
  test_split: 0.15   # 750 test
  cache_dir: "./data/cache"
  quality_filter_enabled: true  # Enable quality filtering
  
# Quality Filter Configuration
quality_filter:
  min_code_length: 20        # Minimum code characters
  max_code_length: 2000      # Maximum code characters
  min_summary_length: 10     # Minimum summary characters
  max_summary_length: 500    # Maximum summary characters
  min_summary_words: 3       # Minimum words in summary
  max_summary_words: 100     # Maximum words in summary
  min_code_lines: 2          # Minimum code lines
  max_code_lines: 100        # Maximum code lines
  
# Model Configuration
model:
  name: "google/gemma-2b"
  quantization: "4bit"
  load_in_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true
  
# LoRA Configuration
lora:
  r: 16
  lora_alpha: 32
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

# Training Configuration
training:
  output_dir: "./outputs"
  num_epochs: 3
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  weight_decay: 0.01
  warmup_steps: 350  # Increased for 5000 samples (~10% of training steps)
  logging_steps: 10
  save_steps: 500    # Adjusted for larger dataset size
  eval_steps: 500
  save_total_limit: 2
  fp16: true
  optim: "paged_adamw_8bit"
  max_grad_norm: 0.3
  max_seq_length: 512
  
# RAG Configuration - DISABLED (causing irrelevant summaries)
rag:
  enabled: false  # Disabled - retrieval contaminating summaries
  embedding_model: "microsoft/codebert-base"
  vector_store: "faiss"
  top_k: 2
  chunk_size: 512
  embedding_dim: 768
  index_path: "./data/rag_index"
  
# Structure Extraction Configuration
structure:
  extract_ast: false  # Disabled - too verbose
  extract_cfg: false  # Disabled - too verbose
  extract_pdg: false  # Disabled - too verbose
  use_compact_summary: true  # Use compact summarizer
  max_ast_depth: 10
  max_cfg_nodes: 50
  max_pdg_nodes: 50
  
# Reflective Agent Configuration - FIXED
reflective_agent:
  enabled: true  # Re-enabled with fixes
  max_iterations: 3  # For training/inference
  max_iterations_eval: 1  # For evaluation (faster, 2-3x speedup)
  criteria:
    - "accuracy"      # Does it match what the code does?
    - "completeness"  # Covers main points?
    - "clarity"       # Easy to understand?
  threshold_score: 0.7  # Lowered from 0.8 for easier approval
  temperature: 0.7
  # Fast mode settings for evaluation
  fast_mode: false  # Enable for faster evaluation
  greedy_decoding: false  # Use greedy instead of sampling (30-50% faster)
  max_tokens_critique: 250  # Moderate limit with structured prompt
  max_tokens_refinement: 300  # Enough for complete docstrings
  
# Evaluation Configuration
evaluation:
  metrics:
    - "bleu"
    - "rouge"
    - "meteor"
  output_dir: "./evaluation_results"
  
# Prompts - IMPROVED for natural language generation
prompts:
  system_prompt: |
    You are an expert at writing clear, concise Python docstrings. Generate ONLY the docstring text in natural language. Do NOT include code, function definitions, or technical syntax.
    
  instruction_template: |
    Write a natural language description of what this function does. Do NOT write code examples.
    
    Function code:
    ```python
    {code}
    ```
    
    {structure_summary}
    
    Write 2-3 sentences describing:
    - What the function does
    - Key parameters and their purpose
    - What it returns
    
    IMPORTANT: Write in plain English sentences. Do NOT include:
    - Code examples (no >>> or function calls)
    - Code syntax (no if/else code)
    - Parameter lists with colons
    
    Description:
    
  reflective_agent_prompt: |
    Review this docstring against the code. Approve if it accurately describes what the code does.
    
    Code:
    {code}
    
    Docstring:
    {draft_summary}
    
    Check if the docstring:
    1. Describes what the function does
    2. Mentions all parameters (if any)
    3. Describes conditional logic (if the code has if/else)
    4. Describes what it returns (if it returns something)
    5. Is accurate (no wrong information)
    
    If the docstring covers everything that EXISTS in the code: respond "APPROVED"
    If something important is MISSING or WRONG: respond "NOT APPROVED - Missing: [what's missing]"
    
    Keep response under 40 words.
    
  refinement_prompt: |
    Improve this docstring based on feedback. Write in natural language only.
    
    Code:
    {code}
    
    Current docstring:
    {draft_summary}
    
    Feedback:
    {feedback}
    
    Write improved docstring (2-4 sentences, plain English, address feedback):
