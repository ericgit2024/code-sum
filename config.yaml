# Configuration for Source Code Summarization Project

# Dataset Configuration
dataset:
  name: "code_x_glue_ct_code_to_text"
  language: "python"
  sample_size: 1000  # Scaled from 500 for better results
  train_split: 0.7   # 700 train
  val_split: 0.15    # 150 val
  test_split: 0.15   # 150 test
  cache_dir: "./data/cache"
  
# Model Configuration
model:
  name: "google/gemma-2b"
  quantization: "4bit"
  load_in_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true
  
# LoRA Configuration
lora:
  r: 16
  lora_alpha: 32
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

# Training Configuration
training:
  output_dir: "./outputs"
  num_epochs: 3
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  weight_decay: 0.01
  warmup_steps: 100  # Increased for 1000 samples
  logging_steps: 10
  save_steps: 200    # Adjusted for dataset size
  eval_steps: 200
  save_total_limit: 2
  fp16: true
  optim: "paged_adamw_8bit"
  max_grad_norm: 0.3
  max_seq_length: 512
  
# RAG Configuration - DISABLED (causing irrelevant summaries)
rag:
  enabled: false  # Disabled - retrieval contaminating summaries
  embedding_model: "microsoft/codebert-base"
  vector_store: "faiss"
  top_k: 2
  chunk_size: 512
  embedding_dim: 768
  index_path: "./data/rag_index"
  
# Structure Extraction Configuration
structure:
  extract_ast: false  # Disabled - too verbose
  extract_cfg: false  # Disabled - too verbose
  extract_pdg: false  # Disabled - too verbose
  use_compact_summary: true  # Use compact summarizer
  max_ast_depth: 10
  max_cfg_nodes: 50
  max_pdg_nodes: 50
  
# Reflective Agent Configuration - IMPROVED
reflective_agent:
  enabled: true  # Re-enabled with better criteria
  max_iterations: 3
  criteria:
    - "accuracy"         # Does it match what the code does?
    - "completeness"     # Covers parameters, return value, purpose?
    - "conciseness"      # Brief, no redundancy?
    - "natural_language" # NO code, NO syntax?
    - "relevance"        # Related to THIS function, not others?
  threshold_score: 0.8
  temperature: 0.7
  
# Evaluation Configuration
evaluation:
  metrics:
    - "bleu"
    - "rouge"
    - "meteor"
  output_dir: "./evaluation_results"
  
# Prompts - IMPROVED for natural language generation
prompts:
  system_prompt: |
    You are an expert at writing clear, concise Python docstrings. Generate ONLY the docstring text in natural language. Do NOT include code, function definitions, or technical syntax.
    
  instruction_template: |
    Write a clear docstring for this Python function. Describe what it does, its parameters, and what it returns. Use natural language only.
    
    Function code:
    ```python
    {code}
    ```
    
    {structure_summary}
    
    Docstring (natural language only):
    
  reflective_agent_prompt: |
    Review this docstring and check if it meets these criteria:
    1. Accuracy: Correctly describes what the code does
    2. Completeness: Covers the function's purpose, parameters, and return value
    3. Conciseness: Brief and to the point, no redundancy
    4. Natural language: NO code, NO syntax, ONLY plain English
    5. Relevance: Describes THIS specific function, not a different one
    
    Code:
    {code}
    
    Docstring:
    {draft_summary}
    
    If it meets ALL criteria, respond with "APPROVED". Otherwise, list specific improvements needed.
    
  refinement_prompt: |
    Improve this docstring based on the feedback. Write ONLY natural language description, NO code.
    
    Code:
    {code}
    
    Current docstring:
    {draft_summary}
    
    Feedback:
    {feedback}
    
    Improved docstring (natural language only):
