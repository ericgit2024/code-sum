# Configuration for Source Code Summarization Project

# Dataset Configuration
dataset:
  name: "code_x_glue_ct_code_to_text"
  language: "python"
  sample_size: 5000  # Scaled to 5000 for improved performance
  train_split: 0.7   # 3500 train
  val_split: 0.15    # 750 val
  test_split: 0.15   # 750 test
  cache_dir: "./data/cache"
  quality_filter_enabled: true  # Enable quality filtering
  
# Quality Filter Configuration
quality_filter:
  min_code_length: 20        # Minimum code characters
  max_code_length: 2000      # Maximum code characters
  min_summary_length: 10     # Minimum summary characters
  max_summary_length: 500    # Maximum summary characters
  min_summary_words: 3       # Minimum words in summary
  max_summary_words: 100     # Maximum words in summary
  min_code_lines: 2          # Minimum code lines
  max_code_lines: 100        # Maximum code lines
  
# Model Configuration
model:
  name: "google/gemma-2b"
  quantization: "4bit"
  load_in_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true
  
# LoRA Configuration
lora:
  r: 16
  lora_alpha: 32
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

# Training Configuration
training:
  output_dir: "./outputs"
  num_epochs: 3
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  weight_decay: 0.01
  warmup_steps: 350  # Increased for 5000 samples (~10% of training steps)
  logging_steps: 10
  save_steps: 500    # Adjusted for larger dataset size
  eval_steps: 500
  save_total_limit: 2
  fp16: true
  optim: "paged_adamw_8bit"
  max_grad_norm: 0.3
  max_seq_length: 512
  
# RAG Configuration
rag:
  enabled: false  # DISABLED - Phase 1 showed contamination issue (BLEU dropped from 0.185 to 0.047)
  embedding_model: "microsoft/codebert-base"
  vector_store: "faiss"
  top_k: 2
  chunk_size: 512
  embedding_dim: 768
  index_path: "./data/rag_index"
  
# Structure Extraction Configuration
structure:
  extract_ast: false  # Disabled - too verbose
  extract_cfg: false  # Disabled - too verbose
  extract_pdg: false  # Disabled - too verbose
  use_compact_summary: true  # Use compact summarizer
  max_ast_depth: 10
  max_cfg_nodes: 50
  max_pdg_nodes: 50
  
# Iteration Agent Configuration (Phase 1 Innovation)
iteration_agent:
  enabled: true  # Single-pass validation and refinement
  validation:
    check_parameters: true
    check_return_value: true
    check_control_flow: true
    check_function_calls: true
    check_naturalness: true
  instruction_generation:
    max_instructions: 4  # 3-4 sentences
    temperature: 0.7
  constrained_refinement:
    strategy: "additive"  # Only add words, don't remove
    max_new_tokens: 150
    temperature: 0.7

# Reflective Agent Configuration - DISABLED for Phase 1
reflective_agent:
  enabled: false  # Replaced by iteration agent
  max_iterations: 3  # For training/inference (base value, adjusted by complexity)
  max_iterations_eval: 3  # For evaluation (increased for better quality)
  criteria:
    - "accuracy"      # Does it match what the code does?
    - "completeness"  # Covers main points?
    - "naturalness"   # Plain English, no code syntax?
    - "conciseness"   # Clear and concise?
  threshold_score: 0.7  # Lowered from 0.8 for easier approval
  temperature: 0.7
  # Fast mode settings for evaluation
  fast_mode: false  # Enable for faster evaluation
  greedy_decoding: false  # Use greedy instead of sampling (30-50% faster)
  max_tokens_critique: 250  # Moderate limit with structured prompt
  max_tokens_refinement: 300  # Enough for complete docstrings
  
  # Multi-Criteria Scoring System (ENABLED for complete solution)
  scoring:
    enabled: true  # ENABLED - Weighted multi-criteria evaluation
    weights:
      accuracy: 0.35      # Most important - correctness
      completeness: 0.30  # Second - covers all aspects
      naturalness: 0.20   # Third - readable prose
      conciseness: 0.15   # Fourth - not too verbose
    approval_threshold: 0.75    # Minimum weighted score to approve
    early_stop_threshold: 0.90  # Stop if score exceeds this
    min_improvement: 0.05       # Stop if improvement less than this
  
  # Adaptive Iteration Strategy (Phase 2 - DISABLED for Phase 1 baseline)
  adaptive_iterations:
    enabled: false  # DISABLED - Phase 1 used fixed 3 iterations
    complexity_thresholds:
      simple: 1      # Functions with cyclomatic complexity <= 3
      moderate: 2    # Functions with cyclomatic complexity 4-8
      complex: 3     # Functions with cyclomatic complexity > 8

# Uncertainty-Aware Summarization (Option 6)
uncertainty_agent:
  enabled: false  # Enable for uncertainty-aware generation
  n_samples: 5    # Number of Monte Carlo samples (5-10 recommended)
  confidence_threshold: 0.6  # Refine sentences below this score
  max_refinement_iterations: 2  # Max times to refine uncertain parts
  
  # Performance note: Enabling this increases inference time by ~5x
  # Expected BLEU improvement: +0.01-0.02
  
# Evaluation Configuration
evaluation:
  metrics:
    - "bleu"
    - "rouge"
    - "meteor"
    - "bertscore"  # Semantic similarity metric
  use_bertscore: true  # Enable/disable BERTScore (requires bert-score package)
  output_dir: "./evaluation_results"
  
# Prompts - IMPROVED for natural language generation
prompts:
  system_prompt: |
    You are a code documentation expert. Generate concise Python docstrings that describe what functions do.
    
  instruction_template: |
    Generate a concise docstring for this function. Write 1-2 sentences maximum.
    
    Function code:
    ```python
    {code}
    ```
    
    {structure_summary}
    
    Docstring (1-2 sentences, describe what it does):
    
  reflective_agent_prompt: |
    Review this docstring against the code. Rate it on each criterion with a score from 0.0 to 1.0.
    
    Code:
    {code}
    
    Docstring:
    {draft_summary}
    
    Rate each criterion (0.0 = poor, 1.0 = excellent):
    
    Accuracy: [score] - Does it correctly describe what the code actually does? No hallucinations?
    Completeness: [score] - Covers parameters (if any), return value (if any), and key logic (if/else, loops)?
    Naturalness: [score] - Written in plain English? No code syntax like if/else, ==, or function calls?
    Conciseness: [score] - Clear and to the point? Not overly verbose or repetitive?
    
    Overall Decision: APPROVED or NOT APPROVED
    If NOT APPROVED, briefly explain what needs improvement (1 sentence).
    
  refinement_prompt: |
    Improve this docstring based on feedback. Write in natural language only.
    
    Code:
    {code}
    
    Current docstring:
    {draft_summary}
    
    Feedback:
    {feedback}
    
    Write improved docstring (2-4 sentences, plain English, address feedback):
  
  # Iteration Agent Prompts
  validation_prompt: |
    Analyze this docstring against the code and identify what's missing or unclear.
    
    Code:
    ```python
    {code}
    ```
    
    Structure: {structure_summary}
    
    Docstring:
    {docstring}
    
    Check:
    1. Are all parameters mentioned? List any missing.
    2. Is the return value/type mentioned? 
    3. Are key control flows mentioned (if/else, loops, error handling)?
    4. Are important function calls mentioned?
    5. Is it written in natural language (no code syntax)?
    
    Report issues found (be specific):
    
  edit_instruction_prompt: |
    Based on these validation issues, write 3-4 sentences describing what to ADD to improve the docstring.
    
    Current docstring:
    {docstring}
    
    Issues found:
    {validation_report}
    
    Edit instructions (3-4 sentences, what to add/clarify):
    
  constrained_refinement_prompt: |
    Improve this docstring by ADDING the suggested information. Keep ALL original words and phrases.
    
    Original docstring:
    {original_docstring}
    
    What to add:
    {edit_instructions}
    
    Code context:
    ```python
    {code}
    ```
    
    IMPORTANT: Keep all words from the original docstring and add new information naturally.
    
    Write the improved docstring:
